{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtMyI/wTI4/UmYSICWqQ0Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kvgopichand1/food_reciepe/blob/main/Food_receipe_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9EjsX8Yx2FZ",
        "outputId": "9ddf41a1-be01-4f74-dbdf-65ef83803f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating pizza recipe generator...\n",
            "Preparing data...\n",
            "Vocabulary size: 69\n",
            "Training model...\n",
            "Epoch 1/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - accuracy: 0.0768 - loss: 4.0386 - val_accuracy: 0.1068 - val_loss: 3.4749\n",
            "Epoch 2/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.1714 - loss: 3.2680 - val_accuracy: 0.2534 - val_loss: 2.8471\n",
            "Epoch 3/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.2458 - loss: 2.7400 - val_accuracy: 0.3466 - val_loss: 2.4626\n",
            "Epoch 4/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.3341 - loss: 2.3619 - val_accuracy: 0.4161 - val_loss: 2.1703\n",
            "Epoch 5/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.4187 - loss: 2.0423 - val_accuracy: 0.4472 - val_loss: 1.9011\n",
            "Epoch 6/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.4447 - loss: 1.7866 - val_accuracy: 0.4559 - val_loss: 1.6631\n",
            "Epoch 7/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.5008 - loss: 1.5810 - val_accuracy: 0.5230 - val_loss: 1.4673\n",
            "Epoch 8/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.5499 - loss: 1.3706 - val_accuracy: 0.5764 - val_loss: 1.2744\n",
            "Epoch 9/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - accuracy: 0.6287 - loss: 1.1701 - val_accuracy: 0.6373 - val_loss: 1.0815\n",
            "Epoch 10/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.6925 - loss: 0.9864 - val_accuracy: 0.7516 - val_loss: 0.9174\n",
            "Epoch 11/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.7949 - loss: 0.8422 - val_accuracy: 0.8758 - val_loss: 0.7449\n",
            "Epoch 12/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8619 - loss: 0.6584 - val_accuracy: 0.8907 - val_loss: 0.5959\n",
            "Epoch 13/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.8856 - loss: 0.5433 - val_accuracy: 0.8857 - val_loss: 0.5015\n",
            "Epoch 14/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9132 - loss: 0.4299 - val_accuracy: 0.9180 - val_loss: 0.3712\n",
            "Epoch 15/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.9251 - loss: 0.3460 - val_accuracy: 0.9329 - val_loss: 0.3000\n",
            "Epoch 16/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.9365 - loss: 0.2886 - val_accuracy: 0.9491 - val_loss: 0.2459\n",
            "Epoch 17/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.9491 - loss: 0.2402 - val_accuracy: 0.9615 - val_loss: 0.2032\n",
            "Epoch 18/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.9547 - loss: 0.1995 - val_accuracy: 0.9702 - val_loss: 0.1695\n",
            "Epoch 19/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - accuracy: 0.9638 - loss: 0.1739 - val_accuracy: 0.9776 - val_loss: 0.1438\n",
            "Epoch 20/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.9697 - loss: 0.1506 - val_accuracy: 0.9652 - val_loss: 0.1282\n",
            "Epoch 21/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 100ms/step - accuracy: 0.9706 - loss: 0.1273 - val_accuracy: 0.9776 - val_loss: 0.1116\n",
            "Epoch 22/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.9760 - loss: 0.1132 - val_accuracy: 0.9702 - val_loss: 0.1163\n",
            "Epoch 23/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.9673 - loss: 0.1306 - val_accuracy: 0.9727 - val_loss: 0.0936\n",
            "Epoch 24/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.9778 - loss: 0.0946 - val_accuracy: 0.9776 - val_loss: 0.0810\n",
            "Epoch 25/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.9809 - loss: 0.0812 - val_accuracy: 0.9776 - val_loss: 0.0681\n",
            "\n",
            "Generated Recipes:\n",
            "\n",
            "Recipe 1:\n",
            "Make pizza dough by mixing combining flour water yeast and salt proof for 2 hours add your favorite toppings bake.\n",
            "--------------------------------------------------\n",
            "\n",
            "Recipe 2:\n",
            "To prepare the dough combine flour water salt rise for 3 hours stretch dough add toppings bake.\n",
            "--------------------------------------------------\n",
            "\n",
            "Recipe 3:\n",
            "Start by mixing flour and flour salt and yeast rest for 1 hour top with vegetables bake.\n",
            "--------------------------------------------------\n",
            "\n",
            "Recipe 4:\n",
            "For a delicious pizza first dough by combining flour water yeast and salt proof for 2 hours add your favorite toppings bake.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "class SimplePizzaGenerator:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = Tokenizer()\n",
        "        self.model = None\n",
        "        self.max_len = 20  # Reduced sequence length for better learning\n",
        "\n",
        "    def create_data(self):\n",
        "        \"\"\"Create basic pizza recipe dataset with more variety\"\"\"\n",
        "        recipes = {\n",
        "            'instructions': [\n",
        "                \"Mix flour water salt yeast to make dough. Let rise for 1 hour. Add toppings. Bake at 450F for 15 minutes.\",\n",
        "                \"Combine flour water yeast salt sugar. Knead for 10 minutes. Rest for 2 hours. Add sauce cheese. Bake 475F 12 minutes.\",\n",
        "                \"Make dough with flour water salt. Rise for 3 hours. Stretch dough. Add toppings. Bake at 500F for 10 minutes.\",\n",
        "                \"Blend flour salt yeast water. Rest overnight. Shape dough. Top with ingredients. Bake at 425F for 20 minutes.\",\n",
        "                \"Prepare dough: mix flour, water, salt, olive oil. Let rise for 1.5 hours. Add tomato sauce and mozzarella. Bake at 400F for 18 minutes.\",\n",
        "                \"Create dough by combining flour, water, yeast, and salt. Proof for 2 hours. Add your favorite toppings. Bake at 475F for 14 minutes.\",\n",
        "                \"Mix whole wheat flour, water, salt, and yeast. Rest for 1 hour. Top with vegetables. Bake at 450F for 16 minutes.\",\n",
        "                \"Combine bread flour, water, salt, and sourdough starter. Ferment for 4 hours. Add toppings. Bake at 500F for 11 minutes.\"\n",
        "            ] * 25  # Repeat to create more samples (200 total)\n",
        "        }\n",
        "        return pd.DataFrame(recipes)\n",
        "\n",
        "    def prepare_data(self, df):\n",
        "        \"\"\"Tokenize and prepare training data\"\"\"\n",
        "        texts = df['instructions'].values\n",
        "        self.tokenizer.fit_on_texts(texts)\n",
        "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "        vocab_size = len(self.tokenizer.word_index) + 1\n",
        "        print(f\"Vocabulary size: {vocab_size}\")\n",
        "\n",
        "        # Create training sequences\n",
        "        input_sequences = []\n",
        "        for sequence in sequences:\n",
        "            for i in range(1, len(sequence)):\n",
        "                n_gram_sequence = sequence[:i+1]\n",
        "                input_sequences.append(n_gram_sequence)\n",
        "\n",
        "        max_sequence_len = max([len(x) for x in input_sequences])\n",
        "        padded_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "\n",
        "        X = padded_sequences[:, :-1]\n",
        "        y = padded_sequences[:, -1]\n",
        "        y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "        return X, y, max_sequence_len\n",
        "\n",
        "    def build_model(self, vocab_size, max_sequence_len):\n",
        "        \"\"\"Improved LSTM model for recipe generation\"\"\"\n",
        "        model = Sequential([\n",
        "            Embedding(vocab_size, 64, input_length=max_sequence_len-1),\n",
        "            LSTM(128, return_sequences=True),\n",
        "            Dropout(0.2),\n",
        "            LSTM(64),\n",
        "            Dense(64, activation='relu'),\n",
        "            Dense(vocab_size, activation='softmax')\n",
        "        ])\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                     optimizer='adam',\n",
        "                     metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def train(self, X, y, max_sequence_len, epochs=30):\n",
        "        \"\"\"Train the model with early stopping\"\"\"\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "        vocab_size = y.shape[1]\n",
        "        self.model = self.build_model(vocab_size, max_sequence_len)\n",
        "\n",
        "        early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "        history = self.model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_test, y_test),\n",
        "            epochs=epochs,\n",
        "            batch_size=64,\n",
        "            callbacks=[early_stop]\n",
        "        )\n",
        "        return history\n",
        "\n",
        "    def generate_recipe(self, start_text, num_words=50):\n",
        "        \"\"\"Generate a new recipe from seed text\"\"\"\n",
        "        if not self.model:\n",
        "            raise Exception(\"Model not trained yet. Call train() first.\")\n",
        "\n",
        "        generated_text = start_text\n",
        "        for _ in range(num_words):\n",
        "            token_list = self.tokenizer.texts_to_sequences([generated_text])[0]\n",
        "            token_list = pad_sequences([token_list], maxlen=self.max_len-1, padding='pre')\n",
        "\n",
        "            predicted_probs = self.model.predict(token_list, verbose=0)\n",
        "            predicted = np.argmax(predicted_probs, axis=-1)[0]\n",
        "\n",
        "            output_word = \"\"\n",
        "            for word, index in self.tokenizer.word_index.items():\n",
        "                if index == predicted:\n",
        "                    output_word = word\n",
        "                    break\n",
        "\n",
        "            generated_text += \" \" + output_word\n",
        "\n",
        "            # Stop if we predict end of sentence or reach max words\n",
        "            if output_word in [\"minutes.\", \"minutes\", \"bake\", \"serve\"] or len(generated_text.split()) >= num_words:\n",
        "                if not generated_text.endswith(\".\"):\n",
        "                    generated_text += \".\"\n",
        "                break\n",
        "\n",
        "        return generated_text.capitalize()\n",
        "\n",
        "def main():\n",
        "    print(\"Creating pizza recipe generator...\")\n",
        "    generator = SimplePizzaGenerator()\n",
        "\n",
        "    # Prepare data\n",
        "    print(\"Preparing data...\")\n",
        "    df = generator.create_data()\n",
        "    X, y, max_seq_len = generator.prepare_data(df)\n",
        "    generator.max_len = max_seq_len  # Update max_len based on actual data\n",
        "\n",
        "    # Train model\n",
        "    print(\"Training model...\")\n",
        "    generator.train(X, y, max_seq_len, epochs=25)\n",
        "\n",
        "    # Generate recipes\n",
        "    print(\"\\nGenerated Recipes:\")\n",
        "    seed_texts = [\n",
        "        \"make pizza dough by mixing\",\n",
        "        \"to prepare the dough combine\",\n",
        "        \"start by mixing flour and\",\n",
        "        \"for a delicious pizza first\"\n",
        "    ]\n",
        "    for i, seed in enumerate(seed_texts):\n",
        "        recipe = generator.generate_recipe(\n",
        "            start_text=seed,\n",
        "            num_words=60\n",
        "        )\n",
        "        print(f\"\\nRecipe {i+1}:\")\n",
        "        print(recipe)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}